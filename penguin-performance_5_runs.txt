Performance Measures 




**********************************************************

RUN 1 

(A) Base-DT Performance Measures 

Hyperparameters: 
 	- criterion: Gini impurity 
	- max_depth: None 
	- min_samples_split: 2 


(B) Confusion Matrix: 
[[43  0  0]
 [ 1 16  0]
 [ 2  0 22]]

(C - D) Classification Report: 
              precision    recall  f1-score   support

           0       0.93      1.00      0.97        43
           1       1.00      0.94      0.97        17
           2       1.00      0.92      0.96        24

    accuracy                           0.96        84
   macro avg       0.98      0.95      0.96        84
weighted avg       0.97      0.96      0.96        84

(C - D) Accuracy Score: 0.9642857142857143

**********************************************************

RUN 2 

(A) Base-DT Performance Measures 

Hyperparameters: 
 	- criterion: Gini impurity 
	- max_depth: None 
	- min_samples_split: 2 


(B) Confusion Matrix: 
[[42  1  0]
 [ 0 17  0]
 [ 2  0 22]]

(C - D) Classification Report: 
              precision    recall  f1-score   support

           0       0.95      0.98      0.97        43
           1       0.94      1.00      0.97        17
           2       1.00      0.92      0.96        24

    accuracy                           0.96        84
   macro avg       0.97      0.96      0.96        84
weighted avg       0.97      0.96      0.96        84

(C - D) Accuracy Score: 0.9642857142857143

**********************************************************

RUN 3 

(A) Base-DT Performance Measures 

Hyperparameters: 
 	- criterion: Gini impurity 
	- max_depth: None 
	- min_samples_split: 2 


(B) Confusion Matrix: 
[[43  0  0]
 [ 0 17  0]
 [ 2  0 22]]

(C - D) Classification Report: 
              precision    recall  f1-score   support

           0       0.96      1.00      0.98        43
           1       1.00      1.00      1.00        17
           2       1.00      0.92      0.96        24

    accuracy                           0.98        84
   macro avg       0.99      0.97      0.98        84
weighted avg       0.98      0.98      0.98        84

(C - D) Accuracy Score: 0.9761904761904762

**********************************************************

RUN 4 

(A) Base-DT Performance Measures 

Hyperparameters: 
 	- criterion: Gini impurity 
	- max_depth: None 
	- min_samples_split: 2 


(B) Confusion Matrix: 
[[43  0  0]
 [ 0 17  0]
 [ 2  0 22]]

(C - D) Classification Report: 
              precision    recall  f1-score   support

           0       0.96      1.00      0.98        43
           1       1.00      1.00      1.00        17
           2       1.00      0.92      0.96        24

    accuracy                           0.98        84
   macro avg       0.99      0.97      0.98        84
weighted avg       0.98      0.98      0.98        84

(C - D) Accuracy Score: 0.9761904761904762

**********************************************************

RUN 5 

(A) Base-DT Performance Measures 

Hyperparameters: 
 	- criterion: Gini impurity 
	- max_depth: None 
	- min_samples_split: 2 


(B) Confusion Matrix: 
[[43  0  0]
 [ 0 17  0]
 [ 2  0 22]]

(C - D) Classification Report: 
              precision    recall  f1-score   support

           0       0.96      1.00      0.98        43
           1       1.00      1.00      1.00        17
           2       1.00      0.92      0.96        24

    accuracy                           0.98        84
   macro avg       0.99      0.97      0.98        84
weighted avg       0.98      0.98      0.98        84

(C - D) Accuracy Score: 0.9761904761904762


**********************************************************

RUN 1 

(A) Top-DT Performance Measures 

{"criterion": "gini", "max_depth": null, "min_samples_split": 6}Hyperparameters: None


(B) Confusion Matrix: 
[[43  0  0]
 [ 0 17  0]
 [ 2  0 22]]

(C - D) Classification Report: 
              precision    recall  f1-score   support

           0       0.96      1.00      0.98        43
           1       1.00      1.00      1.00        17
           2       1.00      0.92      0.96        24

    accuracy                           0.98        84
   macro avg       0.99      0.97      0.98        84
weighted avg       0.98      0.98      0.98        84

(C - D) Accuracy Score: 0.9761904761904762


**********************************************************

RUN 2 

(A) Top-DT Performance Measures 

{"criterion": "gini", "max_depth": 4, "min_samples_split": 6}Hyperparameters: None


(B) Confusion Matrix: 
[[43  0  0]
 [ 0 17  0]
 [ 2  0 22]]

(C - D) Classification Report: 
              precision    recall  f1-score   support

           0       0.96      1.00      0.98        43
           1       1.00      1.00      1.00        17
           2       1.00      0.92      0.96        24

    accuracy                           0.98        84
   macro avg       0.99      0.97      0.98        84
weighted avg       0.98      0.98      0.98        84

(C - D) Accuracy Score: 0.9761904761904762


**********************************************************

RUN 3 

(A) Top-DT Performance Measures 

{"criterion": "gini", "max_depth": null, "min_samples_split": 6}Hyperparameters: None


(B) Confusion Matrix: 
[[43  0  0]
 [ 1 16  0]
 [ 2  0 22]]

(C - D) Classification Report: 
              precision    recall  f1-score   support

           0       0.93      1.00      0.97        43
           1       1.00      0.94      0.97        17
           2       1.00      0.92      0.96        24

    accuracy                           0.96        84
   macro avg       0.98      0.95      0.96        84
weighted avg       0.97      0.96      0.96        84

(C - D) Accuracy Score: 0.9642857142857143


**********************************************************

RUN 4 

(A) Top-DT Performance Measures 

{"criterion": "gini", "max_depth": 4, "min_samples_split": 6}Hyperparameters: None


(B) Confusion Matrix: 
[[43  0  0]
 [ 1 16  0]
 [ 2  0 22]]

(C - D) Classification Report: 
              precision    recall  f1-score   support

           0       0.93      1.00      0.97        43
           1       1.00      0.94      0.97        17
           2       1.00      0.92      0.96        24

    accuracy                           0.96        84
   macro avg       0.98      0.95      0.96        84
weighted avg       0.97      0.96      0.96        84

(C - D) Accuracy Score: 0.9642857142857143


**********************************************************

RUN 5 

(A) Top-DT Performance Measures 

{"criterion": "entropy", "max_depth": null, "min_samples_split": 6}Hyperparameters: None


(B) Confusion Matrix: 
[[42  1  0]
 [ 1 16  0]
 [ 1  1 22]]

(C - D) Classification Report: 
              precision    recall  f1-score   support

           0       0.95      0.98      0.97        43
           1       0.89      0.94      0.91        17
           2       1.00      0.92      0.96        24

    accuracy                           0.95        84
   macro avg       0.95      0.94      0.95        84
weighted avg       0.95      0.95      0.95        84

(C - D) Accuracy Score: 0.9523809523809523


**********************************************************

RUN 1 

(A) Base-MLP Performance Measures 

Hyperparameters: 
 	- hidden_layer_sizes: (100, 100) 
	- activation: logistic 
	- solver: sgd 
	- max_iter = 200 
	- shuffle = true 


(B) Confusion Matrix: 
[[42  1  0]
 [ 1 16  0]
 [ 1  1 22]]

(C - D) Classification Report: 
              precision    recall  f1-score   support

           0       0.95      0.98      0.97        43
           1       0.89      0.94      0.91        17
           2       1.00      0.92      0.96        24

    accuracy                           0.95        84
   macro avg       0.95      0.94      0.95        84
weighted avg       0.95      0.95      0.95        84

(C - D) Accuracy Score: 0.9523809523809523


**********************************************************

RUN 2 

(A) Base-MLP Performance Measures 

Hyperparameters: 
 	- hidden_layer_sizes: (100, 100) 
	- activation: logistic 
	- solver: sgd 
	- max_iter = 200 
	- shuffle = true 


(B) Confusion Matrix: 
[[42  1  0]
 [ 1 16  0]
 [ 1  1 22]]

(C - D) Classification Report: 
              precision    recall  f1-score   support

           0       0.95      0.98      0.97        43
           1       0.89      0.94      0.91        17
           2       1.00      0.92      0.96        24

    accuracy                           0.95        84
   macro avg       0.95      0.94      0.95        84
weighted avg       0.95      0.95      0.95        84

(C - D) Accuracy Score: 0.9523809523809523


**********************************************************

RUN 3 

(A) Base-MLP Performance Measures 

Hyperparameters: 
 	- hidden_layer_sizes: (100, 100) 
	- activation: logistic 
	- solver: sgd 
	- max_iter = 200 
	- shuffle = true 


(B) Confusion Matrix: 
[[42  1  0]
 [ 1 16  0]
 [ 1  1 22]]

(C - D) Classification Report: 
              precision    recall  f1-score   support

           0       0.95      0.98      0.97        43
           1       0.89      0.94      0.91        17
           2       1.00      0.92      0.96        24

    accuracy                           0.95        84
   macro avg       0.95      0.94      0.95        84
weighted avg       0.95      0.95      0.95        84

(C - D) Accuracy Score: 0.9523809523809523


**********************************************************

RUN 4 

(A) Base-MLP Performance Measures 

Hyperparameters: 
 	- hidden_layer_sizes: (100, 100) 
	- activation: logistic 
	- solver: sgd 
	- max_iter = 200 
	- shuffle = true 


(B) Confusion Matrix: 
[[42  1  0]
 [ 1 16  0]
 [ 1  1 22]]

(C - D) Classification Report: 
              precision    recall  f1-score   support

           0       0.95      0.98      0.97        43
           1       0.89      0.94      0.91        17
           2       1.00      0.92      0.96        24

    accuracy                           0.95        84
   macro avg       0.95      0.94      0.95        84
weighted avg       0.95      0.95      0.95        84

(C - D) Accuracy Score: 0.9523809523809523


**********************************************************

RUN 5 

(A) Base-MLP Performance Measures 

Hyperparameters: 
 	- hidden_layer_sizes: (100, 100) 
	- activation: logistic 
	- solver: sgd 
	- max_iter = 200 
	- shuffle = true 


(B) Confusion Matrix: 
[[42  1  0]
 [ 1 16  0]
 [ 1  1 22]]

(C - D) Classification Report: 
              precision    recall  f1-score   support

           0       0.95      0.98      0.97        43
           1       0.89      0.94      0.91        17
           2       1.00      0.92      0.96        24

    accuracy                           0.95        84
   macro avg       0.95      0.94      0.95        84
weighted avg       0.95      0.95      0.95        84

(C - D) Accuracy Score: 0.9523809523809523


**********************************************************

RUN 1 

(A) Top-MLP Performance Measures 

{"activation": "tanh", "hidden_layer_sizes": [200, 200, 200], "max_iter": 800, "solver": "adam"}Hyperparameters: None


(B) Confusion Matrix: 
[[42  1  0]
 [ 1 16  0]
 [ 1  1 22]]

(C - D) Classification Report: 
              precision    recall  f1-score   support

           0       0.95      0.98      0.97        43
           1       0.89      0.94      0.91        17
           2       1.00      0.92      0.96        24

    accuracy                           0.95        84
   macro avg       0.95      0.94      0.95        84
weighted avg       0.95      0.95      0.95        84

(C - D) Accuracy Score: 0.9523809523809523


**********************************************************

RUN 2 

(A) Top-MLP Performance Measures 

{"activation": "logistic", "hidden_layer_sizes": [200, 200, 200], "max_iter": 800, "solver": "adam"}Hyperparameters: None


(B) Confusion Matrix: 
[[42  1  0]
 [ 1 16  0]
 [ 1  1 22]]

(C - D) Classification Report: 
              precision    recall  f1-score   support

           0       0.95      0.98      0.97        43
           1       0.89      0.94      0.91        17
           2       1.00      0.92      0.96        24

    accuracy                           0.95        84
   macro avg       0.95      0.94      0.95        84
weighted avg       0.95      0.95      0.95        84

(C - D) Accuracy Score: 0.9523809523809523


**********************************************************

RUN 3 

(A) Top-MLP Performance Measures 

{"activation": "logistic", "hidden_layer_sizes": [200, 200, 200], "max_iter": 800, "solver": "adam"}Hyperparameters: None


(B) Confusion Matrix: 
[[42  1  0]
 [ 1 16  0]
 [ 1  1 22]]

(C - D) Classification Report: 
              precision    recall  f1-score   support

           0       0.95      0.98      0.97        43
           1       0.89      0.94      0.91        17
           2       1.00      0.92      0.96        24

    accuracy                           0.95        84
   macro avg       0.95      0.94      0.95        84
weighted avg       0.95      0.95      0.95        84

(C - D) Accuracy Score: 0.9523809523809523


**********************************************************

RUN 4 

(A) Top-MLP Performance Measures 

{"activation": "tanh", "hidden_layer_sizes": [200, 200, 200], "max_iter": 800, "solver": "adam"}Hyperparameters: None


(B) Confusion Matrix: 
[[42  1  0]
 [ 1 16  0]
 [ 1  1 22]]

(C - D) Classification Report: 
              precision    recall  f1-score   support

           0       0.95      0.98      0.97        43
           1       0.89      0.94      0.91        17
           2       1.00      0.92      0.96        24

    accuracy                           0.95        84
   macro avg       0.95      0.94      0.95        84
weighted avg       0.95      0.95      0.95        84

(C - D) Accuracy Score: 0.9523809523809523


**********************************************************

RUN 5 

(A) Top-MLP Performance Measures 

{"activation": "logistic", "hidden_layer_sizes": [200, 200, 200], "max_iter": 800, "solver": "adam"}Hyperparameters: None


(B) Confusion Matrix: 
[[42  1  0]
 [ 1 16  0]
 [ 1  1 22]]

(C - D) Classification Report: 
              precision    recall  f1-score   support

           0       0.95      0.98      0.97        43
           1       0.89      0.94      0.91        17
           2       1.00      0.92      0.96        24

    accuracy                           0.95        84
   macro avg       0.95      0.94      0.95        84
weighted avg       0.95      0.95      0.95        84

(C - D) Accuracy Score: 0.9523809523809523


**********************************************************

Overall Performance Measure Averages of the 5 Runs 




*** Base-DT ***
Base-DT Average Accuracy Score: 0.9714285714285713
Base-DT Average Accuracy Score Standard Deviation: 0.0058321184351980224
Base-DT Average Accuracy Score Variance: 3.401360544217663e-05

Base-DT Average F1 Score (Macro): 0.9724907863204445
Base-DT Average F1 Score (Macro) Standard Deviation: 0.006664235524108365
Base-DT Average F1 Score (Macro) Variance: 4.44120351207879e-05

Base-DT Average F1 Score (Weighted): 0.9712326854524557
Base-DT Average F1 Score (Weighted) Standard Deviation: 0.005769491749044583
Base-DT Average F1 Score (Weighted) Variance: 3.3287035042293525e-05


*** Top-DT ***


Top-DT Average Accuracy Score: 0.9666666666666666
Top-DT Average Accuracy Score Standard Deviation: 0.008908708063747483
Top-DT Average Accuracy Score Variance: 7.936507936507943e-05

Top-DT Average F1 Score (Macro): 0.9659290209946343
Top-DT Average F1 Score (Macro) Standard Deviation: 0.011950235596058024
Top-DT Average F1 Score (Macro) Variance: 0.0001428081308012923

Top-DT Average F1 Score (Weighted): 0.9665690055439924
Top-DT Average F1 Score (Weighted) Standard Deviation: 0.008749949349090375
Top-DT Average F1 Score (Weighted) Variance: 7.656161361164708e-05


*** Base-MLP ***


Base-MLP Average Accuracy Score: 0.9523809523809523
Base-MLP Average Accuracy Score Standard Deviation: 0.0
Base-MLP Average Accuracy Score Variance: 0.0

Base-MLP Average F1 Score (Macro): 0.9454415649318199
Base-MLP Average F1 Score (Macro) Standard Deviation: 0.0
Base-MLP Average F1 Score (Macro) Variance: 0.0

Base-MLP Average F1 Score (Weighted): 0.9525788126344992
Base-MLP Average F1 Score (Weighted) Standard Deviation: 0.0
Base-MLP Average F1 Score (Weighted) Variance: 0.0


*** Top-MLP ***


Top-MLP Average Accuracy Score: 0.9523809523809523
Top-MLP Average Accuracy Score Standard Deviation: 0.0
Top-MLP Average Accuracy Score Variance: 0.0

Top-MLP Average F1 Score (Macro): 0.9454415649318199
Top-MLP Average F1 Score (Macro) Standard Deviation: 0.0
Top-MLP Average F1 Score (Macro) Variance: 0.0

Top-MLP Average F1 Score (Weighted): 0.9525788126344992
Top-MLP Average F1 Score (Weighted) Standard Deviation: 0.0
Top-MLP Average F1 Score (Weighted) Variance: 0.0