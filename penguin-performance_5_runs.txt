Performance Measures 




**********************************************************

RUN 1 

(A) Base-DT Performance Measures 

Hyperparameters: 
 	- criterion: Gini impurity 
	- max_depth: None 
	- min_samples_split: 2 


(B) Confusion Matrix: 
[[36  0  1]
 [ 0 19  0]
 [ 0  0 28]]

(C - D) Classification Report: 
              precision    recall  f1-score   support

           0       1.00      0.97      0.99        37
           1       1.00      1.00      1.00        19
           2       0.97      1.00      0.98        28

    accuracy                           0.99        84
   macro avg       0.99      0.99      0.99        84
weighted avg       0.99      0.99      0.99        84

(C - D) Accuracy Score: 0.9880952380952381

**********************************************************

RUN 2 

(A) Base-DT Performance Measures 

Hyperparameters: 
 	- criterion: Gini impurity 
	- max_depth: None 
	- min_samples_split: 2 


(B) Confusion Matrix: 
[[36  1  0]
 [ 0 19  0]
 [ 0  0 28]]

(C - D) Classification Report: 
              precision    recall  f1-score   support

           0       1.00      0.97      0.99        37
           1       0.95      1.00      0.97        19
           2       1.00      1.00      1.00        28

    accuracy                           0.99        84
   macro avg       0.98      0.99      0.99        84
weighted avg       0.99      0.99      0.99        84

(C - D) Accuracy Score: 0.9880952380952381

**********************************************************

RUN 3 

(A) Base-DT Performance Measures 

Hyperparameters: 
 	- criterion: Gini impurity 
	- max_depth: None 
	- min_samples_split: 2 


(B) Confusion Matrix: 
[[36  0  1]
 [ 0 18  1]
 [ 0  0 28]]

(C - D) Classification Report: 
              precision    recall  f1-score   support

           0       1.00      0.97      0.99        37
           1       1.00      0.95      0.97        19
           2       0.93      1.00      0.97        28

    accuracy                           0.98        84
   macro avg       0.98      0.97      0.97        84
weighted avg       0.98      0.98      0.98        84

(C - D) Accuracy Score: 0.9761904761904762

**********************************************************

RUN 4 

(A) Base-DT Performance Measures 

Hyperparameters: 
 	- criterion: Gini impurity 
	- max_depth: None 
	- min_samples_split: 2 


(B) Confusion Matrix: 
[[36  1  0]
 [ 0 19  0]
 [ 0  0 28]]

(C - D) Classification Report: 
              precision    recall  f1-score   support

           0       1.00      0.97      0.99        37
           1       0.95      1.00      0.97        19
           2       1.00      1.00      1.00        28

    accuracy                           0.99        84
   macro avg       0.98      0.99      0.99        84
weighted avg       0.99      0.99      0.99        84

(C - D) Accuracy Score: 0.9880952380952381

**********************************************************

RUN 5 

(A) Base-DT Performance Measures 

Hyperparameters: 
 	- criterion: Gini impurity 
	- max_depth: None 
	- min_samples_split: 2 


(B) Confusion Matrix: 
[[36  0  1]
 [ 0 18  1]
 [ 0  0 28]]

(C - D) Classification Report: 
              precision    recall  f1-score   support

           0       1.00      0.97      0.99        37
           1       1.00      0.95      0.97        19
           2       0.93      1.00      0.97        28

    accuracy                           0.98        84
   macro avg       0.98      0.97      0.97        84
weighted avg       0.98      0.98      0.98        84

(C - D) Accuracy Score: 0.9761904761904762


**********************************************************

RUN 1 

(A) Top-DT Performance Measures 

Hyperparameters: {"criterion": "gini", "max_depth": null, "min_samples_split": 6}


(B) Confusion Matrix: 
[[36  0  1]
 [ 0 19  0]
 [ 0  0 28]]

(C - D) Classification Report: 
              precision    recall  f1-score   support

           0       1.00      0.97      0.99        37
           1       1.00      1.00      1.00        19
           2       0.97      1.00      0.98        28

    accuracy                           0.99        84
   macro avg       0.99      0.99      0.99        84
weighted avg       0.99      0.99      0.99        84

(C - D) Accuracy Score: 0.9880952380952381


**********************************************************

RUN 2 

(A) Top-DT Performance Measures 

Hyperparameters: {"criterion": "gini", "max_depth": 4, "min_samples_split": 6}


(B) Confusion Matrix: 
[[36  0  1]
 [ 0 18  1]
 [ 0  0 28]]

(C - D) Classification Report: 
              precision    recall  f1-score   support

           0       1.00      0.97      0.99        37
           1       1.00      0.95      0.97        19
           2       0.93      1.00      0.97        28

    accuracy                           0.98        84
   macro avg       0.98      0.97      0.97        84
weighted avg       0.98      0.98      0.98        84

(C - D) Accuracy Score: 0.9761904761904762


**********************************************************

RUN 3 

(A) Top-DT Performance Measures 

Hyperparameters: {"criterion": "gini", "max_depth": null, "min_samples_split": 6}


(B) Confusion Matrix: 
[[36  1  0]
 [ 0 19  0]
 [ 0  0 28]]

(C - D) Classification Report: 
              precision    recall  f1-score   support

           0       1.00      0.97      0.99        37
           1       0.95      1.00      0.97        19
           2       1.00      1.00      1.00        28

    accuracy                           0.99        84
   macro avg       0.98      0.99      0.99        84
weighted avg       0.99      0.99      0.99        84

(C - D) Accuracy Score: 0.9880952380952381


**********************************************************

RUN 4 

(A) Top-DT Performance Measures 

Hyperparameters: {"criterion": "gini", "max_depth": null, "min_samples_split": 6}


(B) Confusion Matrix: 
[[36  1  0]
 [ 0 19  0]
 [ 0  0 28]]

(C - D) Classification Report: 
              precision    recall  f1-score   support

           0       1.00      0.97      0.99        37
           1       0.95      1.00      0.97        19
           2       1.00      1.00      1.00        28

    accuracy                           0.99        84
   macro avg       0.98      0.99      0.99        84
weighted avg       0.99      0.99      0.99        84

(C - D) Accuracy Score: 0.9880952380952381


**********************************************************

RUN 5 

(A) Top-DT Performance Measures 

Hyperparameters: {"criterion": "gini", "max_depth": 4, "min_samples_split": 6}


(B) Confusion Matrix: 
[[36  1  0]
 [ 0 19  0]
 [ 0  0 28]]

(C - D) Classification Report: 
              precision    recall  f1-score   support

           0       1.00      0.97      0.99        37
           1       0.95      1.00      0.97        19
           2       1.00      1.00      1.00        28

    accuracy                           0.99        84
   macro avg       0.98      0.99      0.99        84
weighted avg       0.99      0.99      0.99        84

(C - D) Accuracy Score: 0.9880952380952381


**********************************************************

RUN 1 

(A) Base-MLP Performance Measures 

Hyperparameters: 
 	- hidden_layer_sizes: (100, 100) 
	- activation: logistic 
	- solver: sgd 
	- max_iter = 200 
	- shuffle = true 


(B) Confusion Matrix: 
[[36  1  0]
 [ 0 19  0]
 [ 0  0 28]]

(C - D) Classification Report: 
              precision    recall  f1-score   support

           0       1.00      0.97      0.99        37
           1       0.95      1.00      0.97        19
           2       1.00      1.00      1.00        28

    accuracy                           0.99        84
   macro avg       0.98      0.99      0.99        84
weighted avg       0.99      0.99      0.99        84

(C - D) Accuracy Score: 0.9880952380952381


**********************************************************

RUN 2 

(A) Base-MLP Performance Measures 

Hyperparameters: 
 	- hidden_layer_sizes: (100, 100) 
	- activation: logistic 
	- solver: sgd 
	- max_iter = 200 
	- shuffle = true 


(B) Confusion Matrix: 
[[36  1  0]
 [ 0 19  0]
 [ 0  0 28]]

(C - D) Classification Report: 
              precision    recall  f1-score   support

           0       1.00      0.97      0.99        37
           1       0.95      1.00      0.97        19
           2       1.00      1.00      1.00        28

    accuracy                           0.99        84
   macro avg       0.98      0.99      0.99        84
weighted avg       0.99      0.99      0.99        84

(C - D) Accuracy Score: 0.9880952380952381


**********************************************************

RUN 3 

(A) Base-MLP Performance Measures 

Hyperparameters: 
 	- hidden_layer_sizes: (100, 100) 
	- activation: logistic 
	- solver: sgd 
	- max_iter = 200 
	- shuffle = true 


(B) Confusion Matrix: 
[[36  1  0]
 [ 0 19  0]
 [ 0  0 28]]

(C - D) Classification Report: 
              precision    recall  f1-score   support

           0       1.00      0.97      0.99        37
           1       0.95      1.00      0.97        19
           2       1.00      1.00      1.00        28

    accuracy                           0.99        84
   macro avg       0.98      0.99      0.99        84
weighted avg       0.99      0.99      0.99        84

(C - D) Accuracy Score: 0.9880952380952381


**********************************************************

RUN 4 

(A) Base-MLP Performance Measures 

Hyperparameters: 
 	- hidden_layer_sizes: (100, 100) 
	- activation: logistic 
	- solver: sgd 
	- max_iter = 200 
	- shuffle = true 


(B) Confusion Matrix: 
[[36  1  0]
 [ 0 19  0]
 [ 0  0 28]]

(C - D) Classification Report: 
              precision    recall  f1-score   support

           0       1.00      0.97      0.99        37
           1       0.95      1.00      0.97        19
           2       1.00      1.00      1.00        28

    accuracy                           0.99        84
   macro avg       0.98      0.99      0.99        84
weighted avg       0.99      0.99      0.99        84

(C - D) Accuracy Score: 0.9880952380952381


**********************************************************

RUN 5 

(A) Base-MLP Performance Measures 

Hyperparameters: 
 	- hidden_layer_sizes: (100, 100) 
	- activation: logistic 
	- solver: sgd 
	- max_iter = 200 
	- shuffle = true 


(B) Confusion Matrix: 
[[36  1  0]
 [ 0 19  0]
 [ 0  0 28]]

(C - D) Classification Report: 
              precision    recall  f1-score   support

           0       1.00      0.97      0.99        37
           1       0.95      1.00      0.97        19
           2       1.00      1.00      1.00        28

    accuracy                           0.99        84
   macro avg       0.98      0.99      0.99        84
weighted avg       0.99      0.99      0.99        84

(C - D) Accuracy Score: 0.9880952380952381


**********************************************************

RUN 1 

(A) Top-MLP Performance Measures 

Hyperparameters: {"activation": "logistic", "hidden_layer_sizes": [100, 150], "max_iter": 800, "solver": "adam"}


(B) Confusion Matrix: 
[[36  1  0]
 [ 0 19  0]
 [ 0  0 28]]

(C - D) Classification Report: 
              precision    recall  f1-score   support

           0       1.00      0.97      0.99        37
           1       0.95      1.00      0.97        19
           2       1.00      1.00      1.00        28

    accuracy                           0.99        84
   macro avg       0.98      0.99      0.99        84
weighted avg       0.99      0.99      0.99        84

(C - D) Accuracy Score: 0.9880952380952381


**********************************************************

RUN 2 

(A) Top-MLP Performance Measures 

Hyperparameters: {"activation": "logistic", "hidden_layer_sizes": [100, 150], "max_iter": 800, "solver": "adam"}


(B) Confusion Matrix: 
[[36  1  0]
 [ 0 19  0]
 [ 0  0 28]]

(C - D) Classification Report: 
              precision    recall  f1-score   support

           0       1.00      0.97      0.99        37
           1       0.95      1.00      0.97        19
           2       1.00      1.00      1.00        28

    accuracy                           0.99        84
   macro avg       0.98      0.99      0.99        84
weighted avg       0.99      0.99      0.99        84

(C - D) Accuracy Score: 0.9880952380952381


**********************************************************

RUN 3 

(A) Top-MLP Performance Measures 

Hyperparameters: {"activation": "logistic", "hidden_layer_sizes": [100, 150], "max_iter": 800, "solver": "adam"}


(B) Confusion Matrix: 
[[36  1  0]
 [ 0 19  0]
 [ 0  0 28]]

(C - D) Classification Report: 
              precision    recall  f1-score   support

           0       1.00      0.97      0.99        37
           1       0.95      1.00      0.97        19
           2       1.00      1.00      1.00        28

    accuracy                           0.99        84
   macro avg       0.98      0.99      0.99        84
weighted avg       0.99      0.99      0.99        84

(C - D) Accuracy Score: 0.9880952380952381


**********************************************************

RUN 4 

(A) Top-MLP Performance Measures 

Hyperparameters: {"activation": "logistic", "hidden_layer_sizes": [100, 150], "max_iter": 800, "solver": "adam"}


(B) Confusion Matrix: 
[[36  1  0]
 [ 0 19  0]
 [ 0  0 28]]

(C - D) Classification Report: 
              precision    recall  f1-score   support

           0       1.00      0.97      0.99        37
           1       0.95      1.00      0.97        19
           2       1.00      1.00      1.00        28

    accuracy                           0.99        84
   macro avg       0.98      0.99      0.99        84
weighted avg       0.99      0.99      0.99        84

(C - D) Accuracy Score: 0.9880952380952381


**********************************************************

RUN 5 

(A) Top-MLP Performance Measures 

Hyperparameters: {"activation": "logistic", "hidden_layer_sizes": [200, 200, 200], "max_iter": 800, "solver": "adam"}


(B) Confusion Matrix: 
[[36  1  0]
 [ 0 19  0]
 [ 0  0 28]]

(C - D) Classification Report: 
              precision    recall  f1-score   support

           0       1.00      0.97      0.99        37
           1       0.95      1.00      0.97        19
           2       1.00      1.00      1.00        28

    accuracy                           0.99        84
   macro avg       0.98      0.99      0.99        84
weighted avg       0.99      0.99      0.99        84

(C - D) Accuracy Score: 0.9880952380952381


**********************************************************

Overall Performance Measure Averages of the 5 Runs 




*** Base-DT ***
Base-DT Average Accuracy Score: 0.9833333333333334
Base-DT Average Accuracy Score Standard Deviation: 0.005832118435198077
Base-DT Average Accuracy Score Variance: 3.401360544217726e-05

Base-DT Average F1 Score (Macro): 0.9826440911392307
Base-DT Average F1 Score (Macro) Standard Deviation: 0.006374743661843692
Base-DT Average F1 Score (Macro) Variance: 4.063735675421632e-05

Base-DT Average F1 Score (Weighted): 0.9834335830246129
Base-DT Average F1 Score (Weighted) Standard Deviation: 0.005776750266801579
Base-DT Average F1 Score (Weighted) Variance: 3.3370843644992116e-05


*** Top-DT ***


Top-DT Average Accuracy Score: 0.9857142857142858
Top-DT Average Accuracy Score Standard Deviation: 0.004761904761904788
Top-DT Average Accuracy Score Variance: 2.2675736961451502e-05

Top-DT Average F1 Score (Macro): 0.9850353418063434
Top-DT Average F1 Score (Macro) Standard Deviation: 0.005159413736491882
Top-DT Average F1 Score (Macro) Variance: 2.661955010430112e-05

Top-DT Average F1 Score (Weighted): 0.9857951336620256
Top-DT Average F1 Score (Weighted) Standard Deviation: 0.004718318458395744
Top-DT Average F1 Score (Weighted) Variance: 2.2262529074837992e-05


*** Base-MLP ***


Base-MLP Average Accuracy Score: 0.9880952380952381
Base-MLP Average Accuracy Score Standard Deviation: 0.0
Base-MLP Average Accuracy Score Variance: 0.0

Base-MLP Average F1 Score (Macro): 0.9868867814073294
Base-MLP Average F1 Score (Macro) Standard Deviation: 1.1102230246251565e-16
Base-MLP Average F1 Score (Macro) Variance: 1.232595164407831e-32

Base-MLP Average F1 Score (Weighted): 0.9881663237827623
Base-MLP Average F1 Score (Weighted) Standard Deviation: 1.1102230246251565e-16
Base-MLP Average F1 Score (Weighted) Variance: 1.232595164407831e-32


*** Top-MLP ***


Top-MLP Average Accuracy Score: 0.9880952380952381
Top-MLP Average Accuracy Score Standard Deviation: 0.0
Top-MLP Average Accuracy Score Variance: 0.0

Top-MLP Average F1 Score (Macro): 0.9868867814073294
Top-MLP Average F1 Score (Macro) Standard Deviation: 1.1102230246251565e-16
Top-MLP Average F1 Score (Macro) Variance: 1.232595164407831e-32

Top-MLP Average F1 Score (Weighted): 0.9881663237827623
Top-MLP Average F1 Score (Weighted) Standard Deviation: 1.1102230246251565e-16
Top-MLP Average F1 Score (Weighted) Variance: 1.232595164407831e-32