Performance Measures 




**********************************************************

RUN 1 

(A) Base-DT Performance Measures 

Hyperparameters: 
 	- criterion: Gini impurity 
	- max_depth: None 
	- min_samples_split: 2 


(B) Confusion Matrix: 
[[143  51 127]
 [ 55 208  61]
 [154  63 183]]

(C - D) Classification Report: 
              precision    recall  f1-score   support

           0       0.41      0.45      0.42       321
           1       0.65      0.64      0.64       324
           2       0.49      0.46      0.47       400

    accuracy                           0.51      1045
   macro avg       0.52      0.51      0.51      1045
weighted avg       0.51      0.51      0.51      1045

(C - D) Accuracy Score: 0.5110047846889952

**********************************************************

RUN 2 

(A) Base-DT Performance Measures 

Hyperparameters: 
 	- criterion: Gini impurity 
	- max_depth: None 
	- min_samples_split: 2 


(B) Confusion Matrix: 
[[145  48 128]
 [ 57 208  59]
 [154  68 178]]

(C - D) Classification Report: 
              precision    recall  f1-score   support

           0       0.41      0.45      0.43       321
           1       0.64      0.64      0.64       324
           2       0.49      0.45      0.47       400

    accuracy                           0.51      1045
   macro avg       0.51      0.51      0.51      1045
weighted avg       0.51      0.51      0.51      1045

(C - D) Accuracy Score: 0.508133971291866

**********************************************************

RUN 3 

(A) Base-DT Performance Measures 

Hyperparameters: 
 	- criterion: Gini impurity 
	- max_depth: None 
	- min_samples_split: 2 


(B) Confusion Matrix: 
[[143  55 123]
 [ 60 204  60]
 [152  65 183]]

(C - D) Classification Report: 
              precision    recall  f1-score   support

           0       0.40      0.45      0.42       321
           1       0.63      0.63      0.63       324
           2       0.50      0.46      0.48       400

    accuracy                           0.51      1045
   macro avg       0.51      0.51      0.51      1045
weighted avg       0.51      0.51      0.51      1045

(C - D) Accuracy Score: 0.507177033492823

**********************************************************

RUN 4 

(A) Base-DT Performance Measures 

Hyperparameters: 
 	- criterion: Gini impurity 
	- max_depth: None 
	- min_samples_split: 2 


(B) Confusion Matrix: 
[[144  53 124]
 [ 61 209  54]
 [146  63 191]]

(C - D) Classification Report: 
              precision    recall  f1-score   support

           0       0.41      0.45      0.43       321
           1       0.64      0.65      0.64       324
           2       0.52      0.48      0.50       400

    accuracy                           0.52      1045
   macro avg       0.52      0.52      0.52      1045
weighted avg       0.52      0.52      0.52      1045

(C - D) Accuracy Score: 0.5205741626794258

**********************************************************

RUN 5 

(A) Base-DT Performance Measures 

Hyperparameters: 
 	- criterion: Gini impurity 
	- max_depth: None 
	- min_samples_split: 2 


(B) Confusion Matrix: 
[[142  54 125]
 [ 57 211  56]
 [152  66 182]]

(C - D) Classification Report: 
              precision    recall  f1-score   support

           0       0.40      0.44      0.42       321
           1       0.64      0.65      0.64       324
           2       0.50      0.46      0.48       400

    accuracy                           0.51      1045
   macro avg       0.51      0.52      0.51      1045
weighted avg       0.51      0.51      0.51      1045

(C - D) Accuracy Score: 0.5119617224880383


**********************************************************

RUN 1 

(A) Top-DT Performance Measures 

Hyperparameters: {"criterion": "gini", "max_depth": 6, "min_samples_split": 300}


(B) Confusion Matrix: 
[[110  31 180]
 [ 27 234  63]
 [109  62 229]]

(C - D) Classification Report: 
              precision    recall  f1-score   support

           0       0.45      0.34      0.39       321
           1       0.72      0.72      0.72       324
           2       0.49      0.57      0.53       400

    accuracy                           0.55      1045
   macro avg       0.55      0.55      0.54      1045
weighted avg       0.54      0.55      0.54      1045

(C - D) Accuracy Score: 0.5483253588516747


**********************************************************

RUN 2 

(A) Top-DT Performance Measures 

Hyperparameters: {"criterion": "gini", "max_depth": 6, "min_samples_split": 300}


(B) Confusion Matrix: 
[[110  31 180]
 [ 27 234  63]
 [109  62 229]]

(C - D) Classification Report: 
              precision    recall  f1-score   support

           0       0.45      0.34      0.39       321
           1       0.72      0.72      0.72       324
           2       0.49      0.57      0.53       400

    accuracy                           0.55      1045
   macro avg       0.55      0.55      0.54      1045
weighted avg       0.54      0.55      0.54      1045

(C - D) Accuracy Score: 0.5483253588516747


**********************************************************

RUN 3 

(A) Top-DT Performance Measures 

Hyperparameters: {"criterion": "gini", "max_depth": 6, "min_samples_split": 300}


(B) Confusion Matrix: 
[[110  31 180]
 [ 27 234  63]
 [109  62 229]]

(C - D) Classification Report: 
              precision    recall  f1-score   support

           0       0.45      0.34      0.39       321
           1       0.72      0.72      0.72       324
           2       0.49      0.57      0.53       400

    accuracy                           0.55      1045
   macro avg       0.55      0.55      0.54      1045
weighted avg       0.54      0.55      0.54      1045

(C - D) Accuracy Score: 0.5483253588516747


**********************************************************

RUN 4 

(A) Top-DT Performance Measures 

Hyperparameters: {"criterion": "gini", "max_depth": 6, "min_samples_split": 300}


(B) Confusion Matrix: 
[[110  31 180]
 [ 27 234  63]
 [109  62 229]]

(C - D) Classification Report: 
              precision    recall  f1-score   support

           0       0.45      0.34      0.39       321
           1       0.72      0.72      0.72       324
           2       0.49      0.57      0.53       400

    accuracy                           0.55      1045
   macro avg       0.55      0.55      0.54      1045
weighted avg       0.54      0.55      0.54      1045

(C - D) Accuracy Score: 0.5483253588516747


**********************************************************

RUN 5 

(A) Top-DT Performance Measures 

Hyperparameters: {"criterion": "gini", "max_depth": 6, "min_samples_split": 300}


(B) Confusion Matrix: 
[[110  31 180]
 [ 27 234  63]
 [109  62 229]]

(C - D) Classification Report: 
              precision    recall  f1-score   support

           0       0.45      0.34      0.39       321
           1       0.72      0.72      0.72       324
           2       0.49      0.57      0.53       400

    accuracy                           0.55      1045
   macro avg       0.55      0.55      0.54      1045
weighted avg       0.54      0.55      0.54      1045

(C - D) Accuracy Score: 0.5483253588516747


**********************************************************

RUN 1 

(A) Base-MLP Performance Measures 

Hyperparameters: 
 	- hidden_layer_sizes: (100, 100) 
	- activation: logistic 
	- solver: sgd 
	- max_iter = 200 
	- shuffle = true 


(B) Confusion Matrix: 
[[110  31 180]
 [ 27 234  63]
 [109  62 229]]

(C - D) Classification Report: 
              precision    recall  f1-score   support

           0       0.45      0.34      0.39       321
           1       0.72      0.72      0.72       324
           2       0.49      0.57      0.53       400

    accuracy                           0.55      1045
   macro avg       0.55      0.55      0.54      1045
weighted avg       0.54      0.55      0.54      1045

(C - D) Accuracy Score: 0.5483253588516747


**********************************************************

RUN 2 

(A) Base-MLP Performance Measures 

Hyperparameters: 
 	- hidden_layer_sizes: (100, 100) 
	- activation: logistic 
	- solver: sgd 
	- max_iter = 200 
	- shuffle = true 


(B) Confusion Matrix: 
[[110  31 180]
 [ 27 234  63]
 [109  62 229]]

(C - D) Classification Report: 
              precision    recall  f1-score   support

           0       0.45      0.34      0.39       321
           1       0.72      0.72      0.72       324
           2       0.49      0.57      0.53       400

    accuracy                           0.55      1045
   macro avg       0.55      0.55      0.54      1045
weighted avg       0.54      0.55      0.54      1045

(C - D) Accuracy Score: 0.5483253588516747


**********************************************************

RUN 3 

(A) Base-MLP Performance Measures 

Hyperparameters: 
 	- hidden_layer_sizes: (100, 100) 
	- activation: logistic 
	- solver: sgd 
	- max_iter = 200 
	- shuffle = true 


(B) Confusion Matrix: 
[[110  31 180]
 [ 27 234  63]
 [109  62 229]]

(C - D) Classification Report: 
              precision    recall  f1-score   support

           0       0.45      0.34      0.39       321
           1       0.72      0.72      0.72       324
           2       0.49      0.57      0.53       400

    accuracy                           0.55      1045
   macro avg       0.55      0.55      0.54      1045
weighted avg       0.54      0.55      0.54      1045

(C - D) Accuracy Score: 0.5483253588516747


**********************************************************

RUN 4 

(A) Base-MLP Performance Measures 

Hyperparameters: 
 	- hidden_layer_sizes: (100, 100) 
	- activation: logistic 
	- solver: sgd 
	- max_iter = 200 
	- shuffle = true 


(B) Confusion Matrix: 
[[110  31 180]
 [ 27 234  63]
 [109  62 229]]

(C - D) Classification Report: 
              precision    recall  f1-score   support

           0       0.45      0.34      0.39       321
           1       0.72      0.72      0.72       324
           2       0.49      0.57      0.53       400

    accuracy                           0.55      1045
   macro avg       0.55      0.55      0.54      1045
weighted avg       0.54      0.55      0.54      1045

(C - D) Accuracy Score: 0.5483253588516747


**********************************************************

RUN 5 

(A) Base-MLP Performance Measures 

Hyperparameters: 
 	- hidden_layer_sizes: (100, 100) 
	- activation: logistic 
	- solver: sgd 
	- max_iter = 200 
	- shuffle = true 


(B) Confusion Matrix: 
[[110  31 180]
 [ 27 234  63]
 [109  62 229]]

(C - D) Classification Report: 
              precision    recall  f1-score   support

           0       0.45      0.34      0.39       321
           1       0.72      0.72      0.72       324
           2       0.49      0.57      0.53       400

    accuracy                           0.55      1045
   macro avg       0.55      0.55      0.54      1045
weighted avg       0.54      0.55      0.54      1045

(C - D) Accuracy Score: 0.5483253588516747


**********************************************************

RUN 1 

(A) Top-MLP Performance Measures 

Hyperparameters: {"activation": "relu", "hidden_layer_sizes": [100, 150], "max_iter": 1500, "solver": "adam"}


(B) Confusion Matrix: 
[[110  31 180]
 [ 27 234  63]
 [109  62 229]]

(C - D) Classification Report: 
              precision    recall  f1-score   support

           0       0.45      0.34      0.39       321
           1       0.72      0.72      0.72       324
           2       0.49      0.57      0.53       400

    accuracy                           0.55      1045
   macro avg       0.55      0.55      0.54      1045
weighted avg       0.54      0.55      0.54      1045

(C - D) Accuracy Score: 0.5483253588516747


**********************************************************

RUN 2 

(A) Top-MLP Performance Measures 

Hyperparameters: {"activation": "relu", "hidden_layer_sizes": [100, 150], "max_iter": 1500, "solver": "adam"}


(B) Confusion Matrix: 
[[110  31 180]
 [ 27 234  63]
 [109  62 229]]

(C - D) Classification Report: 
              precision    recall  f1-score   support

           0       0.45      0.34      0.39       321
           1       0.72      0.72      0.72       324
           2       0.49      0.57      0.53       400

    accuracy                           0.55      1045
   macro avg       0.55      0.55      0.54      1045
weighted avg       0.54      0.55      0.54      1045

(C - D) Accuracy Score: 0.5483253588516747


**********************************************************

RUN 3 

(A) Top-MLP Performance Measures 

Hyperparameters: {"activation": "relu", "hidden_layer_sizes": [100, 150], "max_iter": 1500, "solver": "adam"}


(B) Confusion Matrix: 
[[110  31 180]
 [ 27 234  63]
 [109  62 229]]

(C - D) Classification Report: 
              precision    recall  f1-score   support

           0       0.45      0.34      0.39       321
           1       0.72      0.72      0.72       324
           2       0.49      0.57      0.53       400

    accuracy                           0.55      1045
   macro avg       0.55      0.55      0.54      1045
weighted avg       0.54      0.55      0.54      1045

(C - D) Accuracy Score: 0.5483253588516747


**********************************************************

RUN 4 

(A) Top-MLP Performance Measures 

Hyperparameters: {"activation": "tanh", "hidden_layer_sizes": [200, 200, 200], "max_iter": 1500, "solver": "adam"}


(B) Confusion Matrix: 
[[110  31 180]
 [ 27 234  63]
 [109  62 229]]

(C - D) Classification Report: 
              precision    recall  f1-score   support

           0       0.45      0.34      0.39       321
           1       0.72      0.72      0.72       324
           2       0.49      0.57      0.53       400

    accuracy                           0.55      1045
   macro avg       0.55      0.55      0.54      1045
weighted avg       0.54      0.55      0.54      1045

(C - D) Accuracy Score: 0.5483253588516747


**********************************************************

RUN 5 

(A) Top-MLP Performance Measures 

Hyperparameters: {"activation": "relu", "hidden_layer_sizes": [200, 200, 200], "max_iter": 1500, "solver": "adam"}


(B) Confusion Matrix: 
[[110  31 180]
 [ 27 234  63]
 [109  62 229]]

(C - D) Classification Report: 
              precision    recall  f1-score   support

           0       0.45      0.34      0.39       321
           1       0.72      0.72      0.72       324
           2       0.49      0.57      0.53       400

    accuracy                           0.55      1045
   macro avg       0.55      0.55      0.54      1045
weighted avg       0.54      0.55      0.54      1045

(C - D) Accuracy Score: 0.5483253588516747


**********************************************************

Overall Performance Measure Averages of the 5 Runs 




*** Base-DT ***
Base-DT Average Accuracy Score: 0.5117703349282297
Base-DT Average Accuracy Score Standard Deviation: 0.004742396820426356
Base-DT Average Accuracy Score Variance: 2.2490327602390006e-05

Base-DT Average F1 Score (Macro): 0.5148792493217724
Base-DT Average F1 Score (Macro) Standard Deviation: 0.004456019912903845
Base-DT Average F1 Score (Macro) Variance: 1.985611346419559e-05

Base-DT Average F1 Score (Weighted): 0.5124782092857921
Base-DT Average F1 Score (Weighted) Standard Deviation: 0.00479203707086785
Base-DT Average F1 Score (Weighted) Variance: 2.296361928857172e-05


*** Top-DT ***


Top-DT Average Accuracy Score: 0.5483253588516747
Top-DT Average Accuracy Score Standard Deviation: 0.0
Top-DT Average Accuracy Score Variance: 0.0

Top-DT Average F1 Score (Macro): 0.5440434738961589
Top-DT Average F1 Score (Macro) Standard Deviation: 0.0
Top-DT Average F1 Score (Macro) Variance: 0.0

Top-DT Average F1 Score (Weighted): 0.5431231259863213
Top-DT Average F1 Score (Weighted) Standard Deviation: 0.0
Top-DT Average F1 Score (Weighted) Variance: 0.0


*** Base-MLP ***


Base-MLP Average Accuracy Score: 0.5483253588516747
Base-MLP Average Accuracy Score Standard Deviation: 0.0
Base-MLP Average Accuracy Score Variance: 0.0

Base-MLP Average F1 Score (Macro): 0.5440434738961589
Base-MLP Average F1 Score (Macro) Standard Deviation: 0.0
Base-MLP Average F1 Score (Macro) Variance: 0.0

Base-MLP Average F1 Score (Weighted): 0.5431231259863213
Base-MLP Average F1 Score (Weighted) Standard Deviation: 0.0
Base-MLP Average F1 Score (Weighted) Variance: 0.0


*** Top-MLP ***


Top-MLP Average Accuracy Score: 0.5483253588516747
Top-MLP Average Accuracy Score Standard Deviation: 0.0
Top-MLP Average Accuracy Score Variance: 0.0

Top-MLP Average F1 Score (Macro): 0.5440434738961589
Top-MLP Average F1 Score (Macro) Standard Deviation: 0.0
Top-MLP Average F1 Score (Macro) Variance: 0.0

Top-MLP Average F1 Score (Weighted): 0.5431231259863213
Top-MLP Average F1 Score (Weighted) Standard Deviation: 0.0
Top-MLP Average F1 Score (Weighted) Variance: 0.0