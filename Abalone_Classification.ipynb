{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abalones_df = pd.read_csv('COMP472-A1-datasets/abalone.csv')\n",
    "# print(penguins_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print csv file info\n",
    "print(abalones_df.info()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # label encoding string values to int\n",
    "le = preprocessing.LabelEncoder()\n",
    "abalones_df['Type'] = le.fit_transform(abalones_df['Type'])\n",
    "\n",
    "print(abalones_df.info()) \n",
    "print(abalones_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the features into 1-hot vectors\n",
    "# abalones_df = pd.get_dummies(abalones_df, columns=['Type'], prefix='Type', dtype='int64')\n",
    "# print(abalones_df.info()) \n",
    "# print(abalones_df.head())\n",
    "\n",
    "# Note we've left this commented out to not affect columns of the table being used for the rest of the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot pie chart based on output class species\n",
    "total = abalones_df['Type'].count()\n",
    "\n",
    "num_females = abalones_df[abalones_df['Type'] == 0]['Type'].count()\n",
    "percent_females= num_females / total * 100\n",
    "\n",
    "num_infants = abalones_df[abalones_df['Type'] == 1]['Type'].count()\n",
    "percent_infants = num_infants / total * 100\n",
    "\n",
    "num_males = abalones_df[abalones_df['Type'] == 2]['Type'].count()\n",
    "percent_males = num_males / total * 100\n",
    "\n",
    "species_percentages = [percent_females, percent_males, percent_infants]\n",
    "\n",
    "plt.figure(figsize=(7, 7))\n",
    "plt.pie(species_percentages, labels=['Females', 'Males', 'Infants'], autopct='%1.1f%%')\n",
    "plt.title(\"Percentange of Each Abalone Type\")\n",
    "plt.savefig('ablone_types_pie_chart.png')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Note: dataset fairly balanced in terms of abalone types\n",
    "\n",
    "# balanced dataset : accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into training and testing sets\n",
    "# default split is 25% testing, 75% training\n",
    "# data is shuffled by default, but no seeding applied \n",
    "\n",
    "X, y = [abalones_df.drop('Type', axis=1), abalones_df['Type']]\n",
    "\n",
    "X_train_set, X_test_set, y_train_set, y_test_set = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base-DT\n",
    "=> a decision tree with the default parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default parameter for criterion = Gini impurity \n",
    "dtc = tree.DecisionTreeClassifier()\n",
    "\n",
    "dtc.fit(X_train_set, y_train_set)\n",
    "tree.plot_tree(dtc, max_depth=6)\n",
    "\n",
    "dot_data = tree.export_graphviz(dtc, out_file=None,\n",
    "    feature_names= ['LongestShell', 'Diameter', 'Height', 'WholeWeight', 'ShuckedWeight', 'VisceraWeight', 'ShellWeight', 'Rings'],\n",
    "    class_names=['F','M','I'],\n",
    "    filled=True, \n",
    "    rounded=True,\n",
    "    max_depth=6,)\n",
    "graph = graphviz.Source(dot_data) \n",
    "\n",
    "graph.render(\"abalone_types_base_dt\")   # save to pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = dtc.predict(X_test_set)\n",
    "\n",
    "print(X_test_set)\n",
    "print(\"Predicted output: \", le.inverse_transform(y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top-DT\n",
    "=> a Decision Tree found using a gridsearch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create decision tree model\n",
    "dtc_top_dt = tree.DecisionTreeClassifier()\n",
    "\n",
    "# define hyperparameters to test for best model\n",
    "hyperparameters = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [None, 6, 2],\n",
    "    'min_samples_split': [35, 150, 300],\n",
    "}\n",
    "\n",
    "# use grid search to find best hyperparameters\n",
    "gs = GridSearchCV(dtc_top_dt, hyperparameters, verbose=1)\n",
    "gs.fit(X_train_set, y_train_set)\n",
    "best_hyperparameters = gs.best_params_\n",
    "\n",
    "print('Best hyperparameters:\\n', best_hyperparameters)\n",
    "\n",
    "# create decision tree model with best hyperparameters\n",
    "dtc_top_dt_best_params = tree.DecisionTreeClassifier(**best_hyperparameters)\n",
    "# train model with best hyperparameters\n",
    "dtc_top_dt_best_params.fit(X_train_set, y_train_set)\n",
    "\n",
    "# plot decision tree\n",
    "tree.plot_tree(dtc_top_dt_best_params)\n",
    "# tree.plot_tree(dtc_top_dt_best_params, max_depth=6)\n",
    "\n",
    "dot_data = tree.export_graphviz(dtc_top_dt_best_params, out_file=None,\n",
    "    feature_names= ['LongestShell', 'Diameter', 'Height', 'WholeWeight', 'ShuckedWeight', 'VisceraWeight', 'ShellWeight', 'Rings'],\n",
    "    class_names=['F','M','I'],\n",
    "    filled=True, \n",
    "    rounded=True,\n",
    "    # max_depth=6,)\n",
    ")\n",
    "graph = graphviz.Source(dot_data) \n",
    "\n",
    "graph.render(\"abalone_types_top_dt\")   # save to pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = dtc_top_dt_best_params.predict(X_test_set)\n",
    "\n",
    "print(X_test_set)\n",
    "print(\"Predicted output: \", le.inverse_transform(y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base-MLP\n",
    "=> a Multi-Layered Perceptron with 2 hidden layers of 100+100 neurons, sigmoid/logistic as activation function, stochastic gradient descent, and default values for the rest of the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top-MLP\n",
    "=> a Multi-Layered Perceptron found using grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
